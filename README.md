# AI-Expedited ASPR Grants: Health IT Summit Presentation

## Overview

This repository contains the presentation files for the AI-Expedited ASPR Grants project, presented at the Health IT Summit in January 2024. The project proposes a solution to expedite grants provided by the Administration for Strategic Preparedness and Response (ASPR) using artificial intelligence.

## Project Team

- Joshua Chambers 
- Pooja Jakkampudi
- Antonia Meier
- Elijah Muzzi
- Esha Vaidya

## Presentation Summary

The presentation is structured as follows:

1. **Introduction to ASPR**: A brief overview of the Administration for Strategic Preparedness and Response and its role in health emergencies and pandemics.
2. **Current Issues with ASPR Grants**: Identifying key bottlenecks and areas for improvement in the current ASPR grant process.
3. **Our Solution**: Introducing our AI-based solution to expedite the grant process, divided into three phases:
   - **Phase 1**: Using BERT (Bidirectional Encoder Representations from Transformers) as a language model to determine "high impact" grants.
   - **Phase 2**: Proactive initiation of the grant process using the National Syndromic Surveillance Program (NSSP) and deep learning classifiers.
   - **Phase 3**: Generating proposal templates with Generative AI based on engineered prompts.
4. **Timeline and Implementation**: A detailed timeline outlining the short-term and long-term steps for implementing the proposed solution.
5. **Short and Long-Term Deliverables**: Expected outcomes and impacts of the solution.

## How to Use This Repository

- The presentation slides are available in the file `Health IT Summit Presentation.pdf`.
- You can download and view the presentation using any software compatible of viewing PDFs.

## References

The presentation includes various references to academic papers, government websites, and articles. Here are some of the key references:

1. Centers for Disease Control and Prevention. (2023). Overview. [Link](https://www.cdc.gov/nssp/overview.html)
2. Devlin J., Chang M.-W., Lee K., & Toutanova K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. [arXiv](https://arxiv.org/abs/1810.04805)
3. Fhirfly. (2023). Transforming healthcare: ClinicalBERT and UMLSBERTâ€™s role in predicting medical codes. [Medium](https://medium.com/@fhirfly/transforming-healthcare-clinicalbert-and-umlsberts-role-in-predicting-medical-codes-from-a6321515d443)

For a full list of references, please refer to the last slide of the presentation.

## Contact

For any questions or further information, please contact:

- Esha Vaidya: 
- Pooja Jakkampudi: 
- Antonia Meier:
- Elijah Muzzi: [emuzzi19@gmail.com](mailto:emuzzi19@gmail.com)
